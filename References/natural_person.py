import json
import pandas as pd
import requests
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from sqlalchemy import create_engine
import urllib


def get_cookies_from_browser(url):
    chrome_options = Options()
    chrome_options.add_argument("--start-maximized")
    driver = webdriver.Chrome(options=chrome_options)
    driver.get(url)
    input("\U0001f310 –ó–∞–π–¥–∏—Ç–µ –Ω–∞ —Å–∞–π—Ç –∏ –Ω–∞–∂–º–∏—Ç–µ Enter –ø–æ—Å–ª–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏...")
    cookies = driver.get_cookies()
    driver.quit()
    return {cookie['name']: cookie['value'] for cookie in cookies}


def fetch_and_flatten(data_url):
    try:
        cookies = get_cookies_from_browser("https://smartup.online")
        print("‚¨áÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
        response = requests.get(data_url, cookies=cookies)
        response.raise_for_status()
        data = response.json()

        if isinstance(data, dict):
            for key, value in data.items():
                if isinstance(value, list):
                    data = value
                    break
            else:
                raise ValueError("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω —Å–ø–∏—Å–æ–∫ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ JSON")
        elif not isinstance(data, list):
            raise ValueError("‚ùå –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω")

        # –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
        main_df = pd.json_normalize(data, sep="_", max_level=1)

        # –†–∞–∑–±–æ—Ä groups
        groups_list = []
        for person in data:
            person_id = person.get("person_id")
            for group in person.get("groups", []):
                group["person_id"] = person_id
                groups_list.append(group)
        groups_df = pd.DataFrame(groups_list)

        # –†–∞–∑–±–æ—Ä rooms
        rooms_list = []
        for person in data:
            person_id = person.get("person_id")
            for room in person.get("rooms", []):
                room["person_id"] = person_id
                rooms_list.append(room)
        rooms_df = pd.DataFrame(rooms_list)

        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ: {len(main_df)} –ø–µ—Ä—Å–æ–Ω, {len(groups_df)} –≥—Ä—É–ø–ø, {len(rooms_df)} –∫–æ–º–Ω–∞—Ç")

        df_dict = {
            name: df for name, df in {
                "natural_person": main_df,
                "natural_person_groups": groups_df,
                "natural_person_rooms": rooms_df
            }.items() if not df.empty and not df.columns.empty
        }

        return df_dict

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {e}")
        return None



def upload_to_sql(df_dict):
    try:
        print("üîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ SQL Server...")
        params = urllib.parse.quote_plus(
            "DRIVER={ODBC Driver 17 for SQL Server};"
            "SERVER=TAKEDA;"
            "DATABASE=DealDB;"
            "Trusted_Connection=yes;"
            "TrustServerCertificate=yes;"
        )
        engine = create_engine(f"mssql+pyodbc:///?odbc_connect={params}")

        for table_name, df in df_dict.items():
            print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≤ —Ç–∞–±–ª–∏—Ü—É: {table_name} ({len(df)} —Å—Ç—Ä–æ–∫)")
            df.to_sql(table_name, con=engine, index=False, if_exists="replace")
        print("‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ SQL Server.")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –≤ SQL: {e}")
        for table_name, df in df_dict.items():
            if df.empty or df.columns.empty:
                print(f"‚è≠ –¢–∞–±–ª–∏—Ü–∞ {table_name} –ø—É—Å—Ç–∞ ‚Äî –ø—Ä–æ–ø—É—â–µ–Ω–æ.")


if __name__ == "__main__":
    DATA_URL = "https://smartup.online/b/anor/mxsx/mr/natural_person$export"
    df_dict = fetch_and_flatten(DATA_URL)
    if df_dict:
        upload_to_sql(df_dict)
